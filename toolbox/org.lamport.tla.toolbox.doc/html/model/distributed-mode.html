<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<!-- This is file org.lamport.tla.toobox.doc/html/model/overview-page.html  -->


<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
 <LINK href="../style.css" rel="stylesheet" type="text/css">

<title>Running TLC in Distributed Mode</title>
</head>
<!-- a comment here -->

<body>
<h1>Running TLC in Distributed Mode</h1>

<pre>
Contents
  <a href="#different-modes">Different modes of Distributed TLC</a>
  <a href="#how-it-works">How Distributed TLC in <i>Ad Hoc</i> Mode Works</a>
  <a href="#running-master">Running the Master</a>
  <a href="#running-workers">Running the Slave Computers</a>
  <a href="#limitations">Limitations of Distributed Mode </a>
  <a href="#help">Getting and Giving Help</a>
</pre>


<a name="different-modes"></a><h2>Different modes of Distributed TLC</h2>

The TLA+ Toolbox has support to run distributed TLC in different modes (<i>ad hoc</i>, <i>Azure</i>, <i>aws-ec2</i>), which can be
generalized into <i>ad hoc</i> mode and <i>Cloud Distributed TLC</i>. The former (ad hoc) runs
TLC on a set of your own computers. It is up to you to install all necessary
prerequisites (<a href="#how-it-works">see below</a>) on each of the computers. The latter mode (Cloud Distributed TLC)
on the other hand, moves Distributed TLC into the <a href="https://en.wikipedia.org/wiki/Cloud_computing">cloud</a>
and thus can automate all the install steps of ad hoc mode for you. It comes at the price service charges by the cloud compute providers.
For Cloud Distributed TLC, please <a href="../cloudtlc/index.html">switch over to its dedicated documentation</a>

<hr>

<a name="how-it-works"></a><h2>How Distributed TLC in <i>Ad Hoc</i> Mode Works</h2>

TLC has a collection of worker threads that do the actual
model checking--that is, they compute the graph of reachable states
and check invariants and other safety properties.&nbsp; There is also
a master thread that coordinates the worker threads.&nbsp; In ordinary
(non-distributed) mode, these threads all run on the same Java Virtual
Machine (JVM) on the same computer as the Toolbox.&nbsp; In
distributed mode, the threads can be run on multiple computers.&nbsp;
The master thread runs on the same computer
as the Toolbox--a computer we call here the <i>master computer</i>.&nbsp;
The threads are run on a collection of <i>slave computers</i>.&nbsp;  Each
slave computer can run multiple threads--the default is to run as many threads
as it has processors (cores).

<p>
TLC keeps fingerprints of all states that it has found, which it uses to
determine if a newly computed state has already been examined.
&nbsp;

It writes the set of fingerprints to disk if it becomes too big to fit
in memory.&nbsp;  Having to read fingerprints from disk slows TLC down
considerably.&nbsp;  As explained below, you can have distributed TLC  distribute the
set of fingerprints to multiple slave computers (instead of keeping them
on the master computer).

</p>

<p>
Unless you're just trying it out, you're running TLC in
distributed mode because your model is quite large.&nbsp;

For any large model, it's a good idea to give TLC as much of the computer's memory
as is not needed by the operating system and other programs that will
be running at the same time.&nbsp;  This applies to TLC being run on the slaves
and on the master if slave fingerprint servers are not used.&nbsp;
</p>


<a name="running-master"></a><h2>Running the Master</h2>

<p>
TLC is run on a <a href="creating-model.html">model</a>.&nbsp;

To specify that it is to be run in distributed mode, select "ad hoc"
in the <i>Run in distributed mode</i> drop down list in the
<a href="overview-page.html#how-to-run">How to run?</a>  section
of the Model Overview Page.  That section also allows you to adjust
the amount of memory allocated to the master.
</p>

<p>
Your master computer is likely to have multiple network interface cards
and thus several different IP addresses. The <i>Master's network address</i>
drop down list shows all IP addresses the Toolbox could identify. Choose the one
to which the workers will be able to connect. The Toolbox tries guess the best
match and selects it by default.
<br>
It is up to you to configure your master's firewall to allow the workers incoming
connections.
</p>

<p> You start a TLC run in distributed mode as usual by clicking on
the <IMG SRC="run-icon.gif" Align="bottom"/> button, by selecting
<i>Run model</i> on the <i>TLC Model Checker</i> menu, or by typing
F11.&nbsp; This should cause the <i>Current status</i> field of the <a
href="results-page.html">Model Checking Results Page</a> to change to
<i>Master is waiting for (remote) workers</i> and then to indicate
that one or more workers have registered with the master.
</p>

<p>
If you want TLC to store the fingerprint set among slave computers,
you must run a (single) <i>fingerprint server</i> on each of them.&nbsp;
Your model must tell TLC how many fingerprint servers it will use.&nbsp;  If you
want fingerprints stored on 5 fingerprint servers (5 slave computers), you increase
the <i>Number of distributed fingerprint sets</i> spinner to 5. Setting it to 0, means
that the master will store the fingerprints. The master uses more memory in this mode.
</p>

<p>
For distributed mode, you may also want to add special arguments to
the command that launches the JVM that runs the master.&nbsp; As
explained <a href="#possible-problem">below</a>, one such argument may
be needed for the master and the workers to communicate.&nbsp; The
arguments are put in the <A href="tlc-options-page.html#jvmargs">JVM arguments</A> field
of the model's TLC Options page, which may be opened via a link on the Model Overview page.
</p>

<p>
If your model will run for a long time (days or weeks), you may not want to
keep the Toolbox open for the entire run.&nbsp;  Instead, you can run TLC from
a command line.&nbsp;

The easiest way to do this is to create the model
in the Toolbox, and <a href="executing-tlc.html#validating">validate it</a>.&nbsp;

You can then run distributed TLC with the following command, where <code>tool-path</code>
is the complete pathname of the directory containing the file <code>tla2tools.jar</code>
and <code>model-path</code> is is the complete pathname of the directory
<code>Spec.toolbox/ModelName</code>, with
<code>Spec</code> the specification's name and <code>ModelName</code>  the model's name
(see  <a href="executing-tlc.html#MC">How TLC is Run</a>):

<pre>
   java  -cp tool-path  tlc2.tool.distributed.TLCServer  model-path/MC
</pre>
Like the  JVM argument <code>-cp tool-path</code>, other JVM arguments can come between <code>java</code>
and <code>tlc2.tool.distributed.TLCServer</code> in this command. TLC options follow
<code>model-path/MC</code>.
<!--
 E.g. with the
<a href="executing-tlc.html#MC">model's subdirectory of the <code>.toolbox</code> directory</a>
and the Toolbox's installation directory in /opt, the command line will look like:
<pre>
   java -cp /opt/toolbox/plugins/org.lamport.tlatools_1.0.0.201211261208 -Dtlc2.tool.distributed.TLCServer.expectedFPSetCount=5 tlc2.tool.distributed.TLCServer /home/user/DieHard/DieHard.toolbox/Model_1/MC
</pre>
-->
</p>

<a name="running-workers"></a><h2>Running the Slave Computers</h2>

<p>
The following are the basic steps that must be accomplished to start
the slaves.&nbsp;  The details of how these steps are performed will vary
according to the operating system and network configuration that you
are using.&nbsp;  If you have trouble getting distributed TLC to
work on your system, try finding help on the
  <A href="https://groups.google.com/forum/?fromgroups#!forum/tlaplus">TLA+ Google group</a>.
</p>

<p>
To run the slaves, you must have a network of computers that can
communicate with one another and with the machine running the master
and the Toolbox.&nbsp;  We assume that there is some some remote
management/administration system installed on the computers that run
the workers.&nbsp;  Examples of such a system are Remote Desktop (Windows),
ssh, rsh, and telnet.&nbsp;  A Java Runtime Environment (JRE), version 11
or later, must also be installed on the machines.&nbsp;
</p>

<p>
  Start the Toolbox on the master computer, and then open a web browser to the URL
  <pre>
      http://master-computer:10996
  </pre>
  where <code>master-computer</code> is the name (or IP address) of the master computer.
  <br/>
  <br/>
  The resulting web page will have further instructions concerning running slaves, however the gist
  of it is:
  <br/>
  <br/>
  <dd>
  Start the Toolbox on the master computer.&nbsp;  Then do the following on a
  shell on each slave computer:
  <pre>
     wget http://master-computer:10996/files/tla2tools.jar
  </pre>
  Then execute one of the following commands in that slave's shell:
  <ul>
  <li> To run just worker threads on the slave, execute:
  <pre>
    java -cp tla2tools.jar tlc2.tool.distributed.TLCWorker master-computer
  </pre>
  </li>

  <li> To run just a fingerprint server on the slave, execute:
  <pre>
    java -cp tla2tools.jar tlc2.tool.distributed.fp.DistributedFPSet master-computer
  </pre>
  </li>

  <li> To run both worker threads and a fingerprint server on the slave, execute:
  <pre>
    java -cp tla2tools.jar tlc2.tool.distributed.fp.TLCWorkerAndFPSet master-computer
  </pre>
  </li>
  </ul>
  <p>
  The <code>wget</code> command downloads the file
  <code>tla2tools.jar</code> into the current directory on the worker
  machine, the <code>java</code> command actually starts the worker.&nbsp; The
  <code>wget</code> command therefore just has to be executed the first
  time you run a worker, and then whenever you install a new version of
  the Toolbox.&nbsp; The <code>wget</code> command is not part of
  Windows, but can be installed on Windows as part of Cygwin.
  <p>

  <p>
  You can add JVM arguments to the <code>java</code> command, such as the argument
  <code>-Xmx7G</code> that
  gives the slave 7 gigabytes of memory.
  </p>
  </dd>
</p>

<p>
By default, each slave that runs workers runs as many worker threads
as it has processors.&nbsp;  Running that many threads on the slave might
cause problems with some operating system.&nbsp;   The following JVM argument causes
each slave to run 2 threads:
<pre>
   -Dtlc2.tool.distributed.TLCWorker.threadCount=2
</pre>
(This JVM argument is only applicable for slaves and has no effect if passed to the master process).
</p>

<h3><a name="possible-problem"></a>A Possible Problem</h3>

The master-computer name you use in the instructions above for running
the workers is usually a name like <code>jones-home-laptop</code> or
<code>tla.msr-inria.inria.fr</code>.&nbsp;  However, some computers have
multiple network interfaces, with different IP addresses--for example,
<code>192.168.1.10</code> and <code>10.10.0.1</code>.&nbsp;  If the master
computer is such a computer, then it's possible that using this name
as the master-computer name in the instructions above will cause the
worker not to be able to communicate with the master because they are
using different IP addresses.&nbsp;  To solve this problem, choose one of
those IP addresses--say <code>192.168.1.10</code>.  Use that address
as the master-computer name in the instructions above for running the
workers, add the following  <A href="tlc-options-page.html#jvmargs">JVM argument</A>
to the model:

<pre>
   -Djava.rmi.server.hostname=192.168.1.10
</pre>

<!--  COMMENTED OUT
<h4>Using Multi-Core Worker Machines</h4>
Currently, workers are single threaded.&nbsp;  You can take advantage of
multi-core computers by running multiple workers on the same computer,
using one of the previous methods to start each of the workers.&nbsp;
The major disadvantage of doing this is that a separate copy of
the worker code is loaded into memory for each worker.
    END COMMENTED OUT -->

<a name="limitations"></a><h2>Limitations of Distributed Mode</h2>

When run in distributed mode, TLC cannot check liveness properties.
Nor does it use depth-first mode or simulation mode, even if one of
those modes is selected on the <a href="tlc-options-page.html">TLC Options Page</a>.&nbsp;

Coverage information is not provided.&nbsp; You should therefore check
a smaller model in ordinary non-distributed mode to make sure that the
specification specifies what you think it does.&nbsp;


<a name="help"></a><h2>Getting and Giving Help</h2>

You may want to run TLC in distributed mode with many workers.&nbsp;
(Preliminary tests suggest that linear speedup is possible even
with hundreds of workers.)&nbsp; Manually starting so many workers is
not practical.&nbsp; It is possible to implement scripts that can
automate the installation of the JRE and one of the two methods
described above for copying the <code>tla2tools.jar</code> file and
starting the workers.&nbsp; How this is done will depend on the
operating system and network configuration.&nbsp;
If you need help, try going to
the <A href="https://groups.google.com/forum/?fromgroups#!forum/tlaplus">TLA+ Google group</a>.

If you have successfully run TLC in distributed mode, please use that
Forum to tell others how you did it on your system.
<hr>
<!-- delete rest of line to comment out
<dl>
<dt><b><font color=#0000c0>Subtopics</font></b></dt>
<dd> <A href="model-values.html"> Model Values and Symmetry </A></dd>
<dd> <a href="distributed-mode.html">Running TLC in Distributed Mode</a></dd>
</dl>
-->
<!-- delete rest of line to comment out -->
<a href = "overview-page.html">&uarr; Model Overview Page</a>
<!-- -->
</hr>

</body>
</html>
